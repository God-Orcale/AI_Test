{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPJm0IZvS7aPUUV+y+9Bg+z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/God-Orcale/AI_Test/blob/main/optimizer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "yFCfdb-qrvIi"
      },
      "outputs": [],
      "source": [
        "# 从前面的数据集和数据加载器部分加载代码，并构建模型。\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root = \"data\",\n",
        "    train = False,\n",
        "    download = True,\n",
        "    transform = ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size = 64)\n",
        "test_dataloader = DataLoader(test_data, batch_size =64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.linear_relu_stack = nn.Sequential(\n",
        "        nn.Linear(28*28, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10)\n",
        "    )\n",
        "\n",
        "  def forward(self,x):\n",
        "      x = self.flatten(x)\n",
        "      logits = self.linear_relu_stack(x)\n",
        "      return logits\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Number of Epochs - 迭代数据集的次数\n",
        "\n",
        "Batch Size - 在更新参数之前通过网络传播的数据样本数\n",
        "\n",
        "学习率 - 在每个批次/epoch 更新模型参数的量。较小的值会导致学习速度变慢，而较大的值可能会导致训练期间出现不可预知的行为。"
      ],
      "metadata": {
        "id": "YOxhlG7VuLBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs= 5\n",
        "\n",
        "# 训练循环 - 迭代训练数据集并尝试收敛到最佳参数。\n",
        "# 验证/测试循环 - 迭代测试数据集以检查模型性能是否正在提高。"
      ],
      "metadata": {
        "id": "2wGis0kquRqc"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 常见的损失函数包括nn.MSELoss（均方误差）用于回归任务，nn.用于分类的NLLLoss。\n",
        "# nn.CrossEntropyLoss结合了nn.LogSoftmax和nn.NLLLoss。\n",
        "# 我们将模型的输出logits传递给nn.CrossEntropyLoss，后者将对logit进行归一化并计算预测误差。\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "5ffP9jhDugdZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们通过注册需要训练的模型参数并传入学习率超参数来初始化优化器。\n",
        "optimizer = torch.optim.SGD(model.parameters(),lr = learning_rate)\n",
        "# 调用optimizer.zero_grad()重置模型参数的梯度。\n",
        "# 默认情况下，梯度累加;为了防止重复计数，我们在每次迭代时都将它们显式归零。\n",
        "# 通过调用loss.backward().PyTorch会根据每个参数来存储损失的梯度。\n",
        "# 一旦我们有了梯度，我们就会调用optimizer.step()以通过在backward pass中收集的梯度来调整参数。"
      ],
      "metadata": {
        "id": "xSzCeWvkvAZr"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_loop(dataloader,model,loss_fn,optimizer):\n",
        "  size = len(dataloader.dataset)\n",
        "  model.train()\n",
        "  for batch,(X,y) in enumerate(dataloader):\n",
        "    pred = model(X)\n",
        "    loss = loss_fn(pred,y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    if batch%100 ==0:\n",
        "      loss,current = loss.item(),batch*batch_size +len(X)\n",
        "      print(f\"loss:{loss:>7f} [{current:>5d}/{size:>5d}]\")\n",
        "def test_loop(dataloader,model,loss_fn):\n",
        "  model.eval()\n",
        "  size = len(dataloader.dataset)\n",
        "  num_batches= len(dataloader)\n",
        "  test_loss,correct = 0,0\n",
        "  with torch.no_grad():\n",
        "    for X,y in dataloader:\n",
        "      pred = model(X)\n",
        "      test_loss +=loss_fn(pred,y).item()\n",
        "      correct += (pred.argmax(1)==y).type(torch.float).sum().item()\n",
        "  test_loss/=num_batches\n",
        "  correct /= size\n",
        "  print(f\"Test Error: \\n  Accuracy:{(100*correct):>0.1f}%,Avg loss:{test_loss:>8f} \\n\")\n"
      ],
      "metadata": {
        "id": "BtOM4cGcvcak"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 我们初始化损失函数和优化器，并将其传递给train_loop和test_loop。\n",
        "# 随意增加epoch的数量来跟踪模型的改进性能。\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "  print(f\"Epoch {t+1}\\n\")\n",
        "  train_loop(train_dataloader,model,loss_fn,optimizer)\n",
        "  test_loop(test_dataloader,model,loss_fn)\n",
        "print(\"DONE!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHXdcW9Hxi-N",
        "outputId": "dd667c08-09d4-42f2-ceec-11bbd08175f0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "\n",
            "loss:0.787227 [   64/60000]\n",
            "loss:0.877057 [ 6464/60000]\n",
            "loss:0.632036 [12864/60000]\n",
            "loss:0.837792 [19264/60000]\n",
            "loss:0.739338 [25664/60000]\n",
            "loss:0.733042 [32064/60000]\n",
            "loss:0.811461 [38464/60000]\n",
            "loss:0.787427 [44864/60000]\n",
            "loss:0.793446 [51264/60000]\n",
            "loss:0.745739 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:72.4%,Avg loss:0.756086 \n",
            "\n",
            "Epoch 2\n",
            "\n",
            "loss:0.748837 [   64/60000]\n",
            "loss:0.845274 [ 6464/60000]\n",
            "loss:0.598966 [12864/60000]\n",
            "loss:0.812405 [19264/60000]\n",
            "loss:0.717305 [25664/60000]\n",
            "loss:0.706948 [32064/60000]\n",
            "loss:0.785652 [38464/60000]\n",
            "loss:0.769672 [44864/60000]\n",
            "loss:0.769983 [51264/60000]\n",
            "loss:0.723540 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:73.4%,Avg loss:0.732871 \n",
            "\n",
            "Epoch 3\n",
            "\n",
            "loss:0.715676 [   64/60000]\n",
            "loss:0.816643 [ 6464/60000]\n",
            "loss:0.570996 [12864/60000]\n",
            "loss:0.791216 [19264/60000]\n",
            "loss:0.698269 [25664/60000]\n",
            "loss:0.685380 [32064/60000]\n",
            "loss:0.762036 [38464/60000]\n",
            "loss:0.754089 [44864/60000]\n",
            "loss:0.750105 [51264/60000]\n",
            "loss:0.703859 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:74.2%,Avg loss:0.712478 \n",
            "\n",
            "Epoch 4\n",
            "\n",
            "loss:0.686547 [   64/60000]\n",
            "loss:0.790555 [ 6464/60000]\n",
            "loss:0.546932 [12864/60000]\n",
            "loss:0.773075 [19264/60000]\n",
            "loss:0.681538 [25664/60000]\n",
            "loss:0.667214 [32064/60000]\n",
            "loss:0.740405 [38464/60000]\n",
            "loss:0.740262 [44864/60000]\n",
            "loss:0.732968 [51264/60000]\n",
            "loss:0.686082 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:75.0%,Avg loss:0.694241 \n",
            "\n",
            "Epoch 5\n",
            "\n",
            "loss:0.660776 [   64/60000]\n",
            "loss:0.766703 [ 6464/60000]\n",
            "loss:0.525974 [12864/60000]\n",
            "loss:0.757158 [19264/60000]\n",
            "loss:0.666790 [25664/60000]\n",
            "loss:0.651837 [32064/60000]\n",
            "loss:0.720425 [38464/60000]\n",
            "loss:0.727953 [44864/60000]\n",
            "loss:0.718166 [51264/60000]\n",
            "loss:0.669759 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:75.8%,Avg loss:0.677736 \n",
            "\n",
            "Epoch 6\n",
            "\n",
            "loss:0.637889 [   64/60000]\n",
            "loss:0.744689 [ 6464/60000]\n",
            "loss:0.507472 [12864/60000]\n",
            "loss:0.742892 [19264/60000]\n",
            "loss:0.653862 [25664/60000]\n",
            "loss:0.638606 [32064/60000]\n",
            "loss:0.701857 [38464/60000]\n",
            "loss:0.717010 [44864/60000]\n",
            "loss:0.705107 [51264/60000]\n",
            "loss:0.654773 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:76.5%,Avg loss:0.662696 \n",
            "\n",
            "Epoch 7\n",
            "\n",
            "loss:0.617435 [   64/60000]\n",
            "loss:0.724451 [ 6464/60000]\n",
            "loss:0.491142 [12864/60000]\n",
            "loss:0.729834 [19264/60000]\n",
            "loss:0.642336 [25664/60000]\n",
            "loss:0.627048 [32064/60000]\n",
            "loss:0.684711 [38464/60000]\n",
            "loss:0.707289 [44864/60000]\n",
            "loss:0.693695 [51264/60000]\n",
            "loss:0.640909 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:77.1%,Avg loss:0.649028 \n",
            "\n",
            "Epoch 8\n",
            "\n",
            "loss:0.599138 [   64/60000]\n",
            "loss:0.705851 [ 6464/60000]\n",
            "loss:0.476586 [12864/60000]\n",
            "loss:0.717862 [19264/60000]\n",
            "loss:0.632192 [25664/60000]\n",
            "loss:0.616874 [32064/60000]\n",
            "loss:0.668735 [38464/60000]\n",
            "loss:0.698794 [44864/60000]\n",
            "loss:0.683790 [51264/60000]\n",
            "loss:0.627951 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:77.6%,Avg loss:0.636539 \n",
            "\n",
            "Epoch 9\n",
            "\n",
            "loss:0.582725 [   64/60000]\n",
            "loss:0.688855 [ 6464/60000]\n",
            "loss:0.463562 [12864/60000]\n",
            "loss:0.706812 [19264/60000]\n",
            "loss:0.623066 [25664/60000]\n",
            "loss:0.607868 [32064/60000]\n",
            "loss:0.653929 [38464/60000]\n",
            "loss:0.691496 [44864/60000]\n",
            "loss:0.675237 [51264/60000]\n",
            "loss:0.615858 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:78.1%,Avg loss:0.625107 \n",
            "\n",
            "Epoch 10\n",
            "\n",
            "loss:0.567870 [   64/60000]\n",
            "loss:0.673271 [ 6464/60000]\n",
            "loss:0.451839 [12864/60000]\n",
            "loss:0.696558 [19264/60000]\n",
            "loss:0.614866 [25664/60000]\n",
            "loss:0.599903 [32064/60000]\n",
            "loss:0.640191 [38464/60000]\n",
            "loss:0.685306 [44864/60000]\n",
            "loss:0.667869 [51264/60000]\n",
            "loss:0.604521 [57664/60000]\n",
            "Test Error: \n",
            "  Accuracy:78.5%,Avg loss:0.614630 \n",
            "\n",
            "DONE!\n"
          ]
        }
      ]
    }
  ]
}